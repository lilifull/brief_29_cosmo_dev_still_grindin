{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71140804",
   "metadata": {},
   "source": [
    "# Prétraitement du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df08d35",
   "metadata": {},
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13faa815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a289636",
   "metadata": {},
   "source": [
    "## Chargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3e38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.max_columns = 10\n",
    "pd.options.display.max_colwidth = 50\n",
    "\n",
    "df = pd.read_csv('./csv/text_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e8890f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>product_name_clean</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>main_category</th>\n",
       "      <th>main_category_num</th>\n",
       "      <th>description_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n",
       "      <td>elegance polyester multicolor abstract eyelet ...</td>\n",
       "      <td>key feature elegance polyester multicolor abst...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "      <td>4</td>\n",
       "      <td>key feature elegance polyester multicolor abst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n",
       "      <td>sathiyas cotton bath towel</td>\n",
       "      <td>specification cotton bath towel bath towel red...</td>\n",
       "      <td>Baby Care</td>\n",
       "      <td>0</td>\n",
       "      <td>specification cotton bath towel bath towel red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74</td>\n",
       "      <td>eurospa cotton terry face towel set</td>\n",
       "      <td>key feature cotton terry face towel set size s...</td>\n",
       "      <td>Baby Care</td>\n",
       "      <td>0</td>\n",
       "      <td>key feature cotton terry face towel set size s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           uniq_id  \\\n",
       "0           0  55b85ea15a1536d46b7190ad6fff8ce7   \n",
       "1           1  7b72c92c2f6c40268628ec5f14c6d590   \n",
       "2           2  64d5d4a258243731dc7bbb1eef49ad74   \n",
       "\n",
       "                                  product_name_clean  \\\n",
       "0  elegance polyester multicolor abstract eyelet ...   \n",
       "1                         sathiyas cotton bath towel   \n",
       "2                eurospa cotton terry face towel set   \n",
       "\n",
       "                                   description_clean    main_category  \\\n",
       "0  key feature elegance polyester multicolor abst...  Home Furnishing   \n",
       "1  specification cotton bath towel bath towel red...        Baby Care   \n",
       "2  key feature cotton terry face towel set size s...        Baby Care   \n",
       "\n",
       "   main_category_num                                   description_name  \n",
       "0                  4  key feature elegance polyester multicolor abst...  \n",
       "1                  0  specification cotton bath towel bath towel red...  \n",
       "2                  0  key feature cotton terry face towel set size s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0229cc7",
   "metadata": {},
   "source": [
    "# Features exctractions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11521e8",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af30538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données pour l'entraînement du modèle Word2Vec\n",
    "sentences = [text.split() for text in df['description_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75008ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(list_of_docs, model, model_wv):\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model_wv:\n",
    "                try:\n",
    "                    vectors.append(model_wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    print(f'Nombre de vecteurs : {len(features)}')\n",
    "    print(f'Taille du vecteur : {len(features[0])}')\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e66b2585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de vecteurs : 1050\n",
      "Taille du vecteur : 300\n"
     ]
    }
   ],
   "source": [
    "# model word2Vec s'entrainant sur les phrases du dataframe\n",
    "local_model = Word2Vec(sentences, vector_size=300, workers=1)\n",
    "local_model_vectors = vectorize(sentences, model=local_model, model_wv=local_model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5851047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement d'un model pré-entrainé \n",
    "pretrain_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c986e86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de vecteurs : 1050\n",
      "Taille du vecteur : 300\n"
     ]
    }
   ],
   "source": [
    "pretrain_model_vectors = vectorize(sentences, model=pretrain_model, model_wv=pretrain_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6517e5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>product_name_clean</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>main_category</th>\n",
       "      <th>main_category_num</th>\n",
       "      <th>description_name</th>\n",
       "      <th>local_vectors_means</th>\n",
       "      <th>pretrain_vectors_means</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n",
       "      <td>elegance polyester multicolor abstract eyelet ...</td>\n",
       "      <td>key feature elegance polyester multicolor abst...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "      <td>4</td>\n",
       "      <td>key feature elegance polyester multicolor abst...</td>\n",
       "      <td>[-0.09874754, 0.19643843, 0.07696229, 0.096146...</td>\n",
       "      <td>[0.048451997, 0.052741077, -0.017014096, 0.035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n",
       "      <td>sathiyas cotton bath towel</td>\n",
       "      <td>specification cotton bath towel bath towel red...</td>\n",
       "      <td>Baby Care</td>\n",
       "      <td>0</td>\n",
       "      <td>specification cotton bath towel bath towel red...</td>\n",
       "      <td>[-0.11512422, 0.22598363, 0.06695108, 0.094727...</td>\n",
       "      <td>[0.018274853, 0.06604099, 0.012273788, 0.05909...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           uniq_id  \\\n",
       "0           0  55b85ea15a1536d46b7190ad6fff8ce7   \n",
       "1           1  7b72c92c2f6c40268628ec5f14c6d590   \n",
       "\n",
       "                                  product_name_clean  \\\n",
       "0  elegance polyester multicolor abstract eyelet ...   \n",
       "1                         sathiyas cotton bath towel   \n",
       "\n",
       "                                   description_clean    main_category  \\\n",
       "0  key feature elegance polyester multicolor abst...  Home Furnishing   \n",
       "1  specification cotton bath towel bath towel red...        Baby Care   \n",
       "\n",
       "   main_category_num                                   description_name  \\\n",
       "0                  4  key feature elegance polyester multicolor abst...   \n",
       "1                  0  specification cotton bath towel bath towel red...   \n",
       "\n",
       "                                 local_vectors_means  \\\n",
       "0  [-0.09874754, 0.19643843, 0.07696229, 0.096146...   \n",
       "1  [-0.11512422, 0.22598363, 0.06695108, 0.094727...   \n",
       "\n",
       "                              pretrain_vectors_means  \n",
       "0  [0.048451997, 0.052741077, -0.017014096, 0.035...  \n",
       "1  [0.018274853, 0.06604099, 0.012273788, 0.05909...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['local_vectors_means'] = local_model_vectors\n",
    "df['pretrain_vectors_means'] = pretrain_model_vectors\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fed08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_accuracy(vectors_columns, model_name):\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(vectors_columns, df.main_category_num, test_size=0.2, random_state=42)\n",
    "    train_data = np.array(train_data.tolist())\n",
    "    test_data = np.array(test_data.tolist())\n",
    "    classifier = SVC()\n",
    "    classifier.fit(train_data,train_labels)\n",
    "    predictions = classifier.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f\"Accuracy with {model_name} : {round((accuracy * 100),2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d162ec6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with word2vec : 45.71%\n",
      "Accuracy with word2vec-google-news-300 : 93.81%\n"
     ]
    }
   ],
   "source": [
    "print_classification_accuracy(df.local_vectors_means, model_name = 'word2vec')\n",
    "print_classification_accuracy(df.pretrain_vectors_means, model_name = 'word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2b28a",
   "metadata": {},
   "source": [
    "Le modèle pré entrainé donne de meilleurs résultats que le modèle entrainé sur les nos datas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
