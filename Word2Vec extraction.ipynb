{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71140804",
   "metadata": {},
   "source": [
    "# Prétraitement du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df08d35",
   "metadata": {},
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13faa815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a289636",
   "metadata": {},
   "source": [
    "## Chargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3e38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.max_columns = 10\n",
    "pd.options.display.max_colwidth = 50\n",
    "\n",
    "df = pd.read_csv('./csv/text_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e8890f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>product_name_clean</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>main_category</th>\n",
       "      <th>main_category_num</th>\n",
       "      <th>description_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n",
       "      <td>elegance polyester multicolor abstract eyelet ...</td>\n",
       "      <td>key feature elegance polyester multicolor abst...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "      <td>4</td>\n",
       "      <td>key feature elegance polyester multicolor abst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n",
       "      <td>sathiyas cotton bath towel</td>\n",
       "      <td>specification cotton bath towel bath towel red...</td>\n",
       "      <td>Baby Care</td>\n",
       "      <td>0</td>\n",
       "      <td>specification cotton bath towel bath towel red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74</td>\n",
       "      <td>eurospa cotton terry face towel set</td>\n",
       "      <td>key feature cotton terry face towel set size s...</td>\n",
       "      <td>Baby Care</td>\n",
       "      <td>0</td>\n",
       "      <td>key feature cotton terry face towel set size s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           uniq_id  \\\n",
       "0           0  55b85ea15a1536d46b7190ad6fff8ce7   \n",
       "1           1  7b72c92c2f6c40268628ec5f14c6d590   \n",
       "2           2  64d5d4a258243731dc7bbb1eef49ad74   \n",
       "\n",
       "                                  product_name_clean  \\\n",
       "0  elegance polyester multicolor abstract eyelet ...   \n",
       "1                         sathiyas cotton bath towel   \n",
       "2                eurospa cotton terry face towel set   \n",
       "\n",
       "                                   description_clean    main_category  \\\n",
       "0  key feature elegance polyester multicolor abst...  Home Furnishing   \n",
       "1  specification cotton bath towel bath towel red...        Baby Care   \n",
       "2  key feature cotton terry face towel set size s...        Baby Care   \n",
       "\n",
       "   main_category_num                                   description_name  \n",
       "0                  4  key feature elegance polyester multicolor abst...  \n",
       "1                  0  specification cotton bath towel bath towel red...  \n",
       "2                  0  key feature cotton terry face towel set size s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838620c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1050 entries, 0 to 1049\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          1050 non-null   int64 \n",
      " 1   uniq_id             1050 non-null   object\n",
      " 2   product_name_clean  1050 non-null   object\n",
      " 3   description_clean   1050 non-null   object\n",
      " 4   main_category       1050 non-null   object\n",
      " 5   main_category_num   1050 non-null   int64 \n",
      " 6   description_name    1050 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 57.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0229cc7",
   "metadata": {},
   "source": [
    "# Features exctractions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11521e8",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af30538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données pour l'entraînement du modèle Word2Vec\n",
    "sentences = [text.split() for text in df['description_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e66b2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model word2Vec s'entrainant sur les phrases du dataframe\n",
    "model = Word2Vec(sentences, vector_size=100, workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75008ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize(list_of_docs, model):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Embedding\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents\n",
    "        model: Gensim's Word Embedding\n",
    "\n",
    "    Returns:\n",
    "        List of document vectors\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "    \n",
    "vectorized_docs = vectorize(sentences, model=model)\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6517e5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>product_name_clean</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>main_category</th>\n",
       "      <th>main_category_num</th>\n",
       "      <th>description_name</th>\n",
       "      <th>vectors_means</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n",
       "      <td>elegance polyester multicolor abstract eyelet ...</td>\n",
       "      <td>key feature elegance polyester multicolor abst...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "      <td>4</td>\n",
       "      <td>key feature elegance polyester multicolor abst...</td>\n",
       "      <td>[-0.10184959, -0.039871898, -0.061881114, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n",
       "      <td>sathiyas cotton bath towel</td>\n",
       "      <td>specification cotton bath towel bath towel red...</td>\n",
       "      <td>Baby Care</td>\n",
       "      <td>0</td>\n",
       "      <td>specification cotton bath towel bath towel red...</td>\n",
       "      <td>[-0.08345177, -0.14484063, -0.07083861, 0.1442...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           uniq_id  \\\n",
       "0           0  55b85ea15a1536d46b7190ad6fff8ce7   \n",
       "1           1  7b72c92c2f6c40268628ec5f14c6d590   \n",
       "\n",
       "                                  product_name_clean  \\\n",
       "0  elegance polyester multicolor abstract eyelet ...   \n",
       "1                         sathiyas cotton bath towel   \n",
       "\n",
       "                                   description_clean    main_category  \\\n",
       "0  key feature elegance polyester multicolor abst...  Home Furnishing   \n",
       "1  specification cotton bath towel bath towel red...        Baby Care   \n",
       "\n",
       "   main_category_num                                   description_name  \\\n",
       "0                  4  key feature elegance polyester multicolor abst...   \n",
       "1                  0  specification cotton bath towel bath towel red...   \n",
       "\n",
       "                                       vectors_means  \n",
       "0  [-0.10184959, -0.039871898, -0.061881114, 0.12...  \n",
       "1  [-0.08345177, -0.14484063, -0.07083861, 0.1442...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vectors_means'] = vectorized_docs\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1f2ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [-0.10184959, -0.039871898, -0.061881114, 0.12...\n",
       "1       [-0.08345177, -0.14484063, -0.07083861, 0.1442...\n",
       "2       [-0.140494, -0.02810181, -0.04000086, 0.143009...\n",
       "3       [-0.04486203, -0.15910017, -0.073009774, 0.116...\n",
       "4       [-0.08563257, -0.10234223, -0.065558225, 0.135...\n",
       "                              ...                        \n",
       "1045    [-0.1534988, 0.076541804, -0.016842853, 0.1115...\n",
       "1046    [-0.19656068, 0.094294995, -0.021363508, 0.148...\n",
       "1047    [-0.5309979, 0.5764248, 0.014826372, 0.3146439...\n",
       "1048    [-0.48244742, 0.52018255, 0.006087722, 0.28895...\n",
       "1049    [-0.541187, 0.5855924, 0.013153279, 0.3191772,...\n",
       "Name: vectors_means, Length: 1050, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vectors_means']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5851047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement d'un model pré-entrainé \n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "481edec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize(list_of_docs, model):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Embedding\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents\n",
    "        model: Gensim's Word Embedding\n",
    "\n",
    "    Returns:\n",
    "        List of document vectors\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in wv:\n",
    "                try:\n",
    "                    vectors.append(wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "    \n",
    "vectorized_docs = vectorize(sentences, model=wv)\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bcab1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.048451997, 0.052741077, -0.017014096, 0.035...\n",
       "1       [0.018274853, 0.06604099, 0.012273788, 0.05909...\n",
       "2       [0.020904202, 0.09313281, 0.00014671043, 0.059...\n",
       "3       [-0.0043165246, 0.051694907, -0.045088943, 0.0...\n",
       "4       [0.010901001, 0.048768923, -0.0025513915, 0.07...\n",
       "                              ...                        \n",
       "1045    [0.013211982, 0.055592205, 0.007732161, 0.0511...\n",
       "1046    [-0.00069127965, 0.053532355, 0.018493427, 0.0...\n",
       "1047    [0.055739265, 0.06684657, -0.038131714, 0.1533...\n",
       "1048    [0.11247452, 0.09372877, 0.0034365447, 0.21565...\n",
       "1049    [0.07366333, 0.099365234, -0.0085723875, 0.187...\n",
       "Name: pre_vectors_means, Length: 1050, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pre_vectors_means'] = vectorized_docs\n",
    "df['pre_vectors_means']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fed08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(X, model_name):\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(X, df.main_category_num, test_size=0.2, random_state=42)\n",
    "    train_data = np.array(train_data.tolist())\n",
    "    test_data = np.array(test_data.tolist())\n",
    "    classifier = SVC()\n",
    "    classifier.fit(train_data,train_labels)\n",
    "    predictions = classifier.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f\"Accuracy with {model_name} : {round((accuracy * 100),2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d7d57c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with word2vec-google-news-300 : 93.81%\n"
     ]
    }
   ],
   "source": [
    "classification_accuracy(df.pre_vectors_means, model_name = 'word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d162ec6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with word2vec : 52.86%\n"
     ]
    }
   ],
   "source": [
    "acc = classification_accuracy(df.vectors_means, model_name = 'word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2b28a",
   "metadata": {},
   "source": [
    "Le modèle pré entrainé donne de meilleurs résultats que le modèle entrainé sur les nos datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6fcbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
