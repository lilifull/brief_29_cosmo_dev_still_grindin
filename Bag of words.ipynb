{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71140804",
   "metadata": {},
   "source": [
    "# Prétraitement du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df08d35",
   "metadata": {},
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "13faa815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing\n",
    "import gensim.downloader as api\n",
    "from seaborn import countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf8b10cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/justinelv/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/justinelv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/justinelv/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/justinelv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a289636",
   "metadata": {},
   "source": [
    "## Chargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ca3e38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.max_columns = 10\n",
    "pd.options.display.max_colwidth = 50\n",
    "\n",
    "df = pd.read_csv('./csv/text_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a7e8890f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>product_name_clean</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>main_category</th>\n",
       "      <th>main_category_num</th>\n",
       "      <th>description_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n",
       "      <td>elegance polyester multicolor abstract eyelet ...</td>\n",
       "      <td>key feature elegance polyester multicolor abst...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "      <td>4</td>\n",
       "      <td>key feature elegance polyester multicolor abst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n",
       "      <td>sathiyas cotton bath towel</td>\n",
       "      <td>specification cotton bath towel bath towel red...</td>\n",
       "      <td>Baby Care</td>\n",
       "      <td>0</td>\n",
       "      <td>specification cotton bath towel bath towel red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74</td>\n",
       "      <td>eurospa cotton terry face towel set</td>\n",
       "      <td>key feature cotton terry face towel set size s...</td>\n",
       "      <td>Baby Care</td>\n",
       "      <td>0</td>\n",
       "      <td>key feature cotton terry face towel set size s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           uniq_id  \\\n",
       "0           0  55b85ea15a1536d46b7190ad6fff8ce7   \n",
       "1           1  7b72c92c2f6c40268628ec5f14c6d590   \n",
       "2           2  64d5d4a258243731dc7bbb1eef49ad74   \n",
       "\n",
       "                                  product_name_clean  \\\n",
       "0  elegance polyester multicolor abstract eyelet ...   \n",
       "1                         sathiyas cotton bath towel   \n",
       "2                eurospa cotton terry face towel set   \n",
       "\n",
       "                                   description_clean    main_category  \\\n",
       "0  key feature elegance polyester multicolor abst...  Home Furnishing   \n",
       "1  specification cotton bath towel bath towel red...        Baby Care   \n",
       "2  key feature cotton terry face towel set size s...        Baby Care   \n",
       "\n",
       "   main_category_num                                   description_name  \n",
       "0                  4  key feature elegance polyester multicolor abst...  \n",
       "1                  0  specification cotton bath towel bath towel red...  \n",
       "2                  0  key feature cotton terry face towel set size s...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "838620c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1050 entries, 0 to 1049\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          1050 non-null   int64 \n",
      " 1   uniq_id             1050 non-null   object\n",
      " 2   product_name_clean  1050 non-null   object\n",
      " 3   description_clean   1050 non-null   object\n",
      " 4   main_category       1050 non-null   object\n",
      " 5   main_category_num   1050 non-null   int64 \n",
      " 6   description_name    1050 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 57.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0229cc7",
   "metadata": {},
   "source": [
    "# Features exctractions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e3ee4",
   "metadata": {},
   "source": [
    "## Bag of words vs TF-IDF (test avec les trois colonnes : description, product_name, description+product_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9bb2e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [CountVectorizer(),TfidfVectorizer()]\n",
    "columns = [df['description_clean'],df['product_name_clean'],df['description_name']]\n",
    "\n",
    "def creat_text_vectors(vectorizer, columns):\n",
    "    \n",
    "    vect = vectorizer\n",
    "    bow = vectorizer.fit_transform(columns)\n",
    "    bow = pd.DataFrame(bow.toarray(),columns = vectorizer.get_feature_names_out())\n",
    "    \n",
    "    return bow\n",
    "\n",
    "all_df = []\n",
    "\n",
    "for vectorizer in vectorizers :\n",
    "    for column in columns:\n",
    "        all_df.append(creat_text_vectors(vectorizer, column))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f937c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Définir les noms de colonnes et de vectorizers\n",
    "column_names = ['description_clean', 'product_name_clean', 'description_name']\n",
    "vectorizer_names = ['CountVectorizer', 'TfidfVectorizer']\n",
    "\n",
    "# Définir les noms de vos dataframes\n",
    "df_names = []\n",
    "for col in column_names:\n",
    "    for vec in vectorizer_names:\n",
    "        df_names.append(f\"{vec}_{col}\")\n",
    "\n",
    "# Définir les combinaisons de colonnes et de vectorizers\n",
    "combinations = [(CountVectorizer(), df['description_clean']),\n",
    "                (CountVectorizer(), df['product_name_clean']),\n",
    "                (CountVectorizer(), df['description_name']),\n",
    "                (TfidfVectorizer(), df['description_clean']),\n",
    "                (TfidfVectorizer(), df['product_name_clean']),\n",
    "                (TfidfVectorizer(), df['description_name'])]\n",
    "\n",
    "# Créer les dataframes et les assigner à des variables avec des noms explicites\n",
    "for i, (vectorizer, column) in enumerate(combinations):\n",
    "    name = df_names[i]\n",
    "    bow = vectorizer.fit_transform(column)\n",
    "    bow = pd.DataFrame(bow.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "    bow.columns = [f\"{name}_{col}\" for col in bow.columns]\n",
    "    globals()[name] = bow\n",
    "\n",
    "# Faire une liste avec les dataframes créés\n",
    "df_list = ['CountVectorizer_description_clean','CountVectorizer_product_name_clean','CountVectorizer_description_name','TfidfVectorizer_description_clean','TfidfVectorizer_product_name_clean','TfidfVectorizer_description_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab9573",
   "metadata": {},
   "source": [
    "### Test CountVectorizer vs TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "90884bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(i):\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(eval(df_names[i]), df.main_category_num, test_size=0.2, random_state=42)\n",
    "    classifier = SVC()\n",
    "    classifier.fit(train_data,train_labels)\n",
    "    predictions = classifier.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f\"Accuracy with {df_names[i]} {round((accuracy * 100),2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8a66b3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with CountVectorizer_description_clean 80.48%\n",
      "Accuracy with TfidfVectorizer_description_clean 89.52%\n",
      "Accuracy with CountVectorizer_product_name_clean 88.1%\n",
      "Accuracy with TfidfVectorizer_product_name_clean 92.38%\n",
      "Accuracy with CountVectorizer_description_name 91.43%\n",
      "Accuracy with TfidfVectorizer_description_name 94.29%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_names)):\n",
    "    classification_accuracy(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538cd1e",
   "metadata": {},
   "source": [
    "La meilleur accuracy pour la classification est avec la méthode Tf-idf avec la colonne qui contient les description et le product name."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
